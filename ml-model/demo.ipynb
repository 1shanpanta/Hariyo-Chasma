{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\n",
      "0: 480x640 2 persons, 596.1ms\n",
      "Speed: 6.0ms preprocess, 596.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 3 persons, 456.0ms\n",
      "Speed: 3.0ms preprocess, 456.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 3.0]\n",
      "\n",
      "0: 480x640 3 persons, 456.9ms\n",
      "Speed: 4.0ms preprocess, 456.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 3.0]\n",
      "\n",
      "0: 480x640 3 persons, 448.9ms\n",
      "Speed: 4.0ms preprocess, 448.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 3.0]\n",
      "\n",
      "0: 480x640 3 persons, 470.9ms\n",
      "Speed: 6.0ms preprocess, 470.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 3.0]\n",
      "\n",
      "0: 480x640 1 carryload, 2 persons, 445.0ms\n",
      "Speed: 5.0ms preprocess, 445.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 0.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 0.0]\n",
      "\n",
      "0: 480x640 2 persons, 446.0ms\n",
      "Speed: 3.0ms preprocess, 446.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 2 persons, 414.0ms\n",
      "Speed: 4.0ms preprocess, 414.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 2 persons, 438.9ms\n",
      "Speed: 2.0ms preprocess, 438.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 3 persons, 430.0ms\n",
      "Speed: 4.0ms preprocess, 430.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 3.0]\n",
      "\n",
      "0: 480x640 2 persons, 444.9ms\n",
      "Speed: 4.0ms preprocess, 444.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 1 person, 444.0ms\n",
      "Speed: 3.0ms preprocess, 444.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0]\n",
      "Garbage thrower!\n",
      "[3.0]\n",
      "\n",
      "0: 480x640 2 persons, 438.9ms\n",
      "Speed: 4.0ms preprocess, 438.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 2 persons, 437.9ms\n",
      "Speed: 4.0ms preprocess, 437.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 1 carryload, 2 persons, 471.9ms\n",
      "Speed: 3.0ms preprocess, 471.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[0.0, 3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[0.0, 3.0, 3.0]\n",
      "\n",
      "0: 480x640 2 persons, 519.9ms\n",
      "Speed: 6.0ms preprocess, 519.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 2 persons, 602.9ms\n",
      "Speed: 6.0ms preprocess, 602.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 2 persons, 593.9ms\n",
      "Speed: 6.0ms preprocess, 593.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 3 persons, 841.9ms\n",
      "Speed: 15.0ms preprocess, 841.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 3.0]\n",
      "\n",
      "0: 480x640 1 carryload, 2 persons, 519.9ms\n",
      "Speed: 5.0ms preprocess, 519.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 0.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 0.0]\n",
      "\n",
      "0: 480x640 3 persons, 435.0ms\n",
      "Speed: 4.0ms preprocess, 435.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 3.0]\n",
      "\n",
      "0: 480x640 1 carryload, 2 persons, 424.0ms\n",
      "Speed: 4.0ms preprocess, 424.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 0.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 0.0]\n",
      "\n",
      "0: 480x640 2 persons, 456.0ms\n",
      "Speed: 3.0ms preprocess, 456.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0]\n",
      "\n",
      "0: 480x640 1 carryload, 3 persons, 434.0ms\n",
      "Speed: 5.0ms preprocess, 434.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0, 0.0, 3.0]\n",
      "Garbage thrower!\n",
      "[3.0, 3.0, 0.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "import torch \n",
    "from pygame import mixer\n",
    "\n",
    "class ObjectDetection:\n",
    "    def __init__(self, source):\n",
    "        \"\"\"Initializes an ObjectDetection instance with a video source (webcam or IP camera URL).\"\"\"\n",
    "        self.source = source\n",
    "\n",
    "        # Model information\n",
    "        # Load YOLOv8n model weights\n",
    "        self.model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "\n",
    "        # Visual information\n",
    "        self.annotator = None\n",
    "        self.start_time = 0\n",
    "        self.end_time = 0\n",
    "\n",
    "        # Device information\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def predict(self, im0):\n",
    "        \"\"\"Run prediction using a YOLO model for the input image im0.\"\"\"\n",
    "        results = self.model(im0)\n",
    "        return results\n",
    "    def alert(self, class_ids):\n",
    "        \"\"\"Send an email alert if a person is detected in the frame.\"\"\"\n",
    "        for i in class_ids:\n",
    "            if i == 1:\n",
    "                # Send email alert\n",
    "                print(\"Garbage thrower!\")\n",
    "                \n",
    "                return True\n",
    "   \n",
    "\n",
    "    def display_fps(self, im0):\n",
    "        \"\"\"Displays the FPS on an image im0 by calculating and overlaying as white text on a black rectangle.\"\"\"\n",
    "        self.end_time = time.time()\n",
    "        fps = 1 / np.round(self.end_time - self.start_time, 2)\n",
    "        text = f'FPS: {int(fps)}'\n",
    "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]\n",
    "        gap = 10\n",
    "        cv2.rectangle(im0, (20 - gap, 70 - text_size[1] - gap),\n",
    "                      (20 + text_size[0] + gap, 70 + gap), (255, 255, 255), -1)\n",
    "        cv2.putText(im0, text, (20, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 2)\n",
    "\n",
    "    def plot_bboxes(self, results, im0):\n",
    "        \"\"\"Plots bounding boxes on an image given detection results; returns annotated image and class IDs.\"\"\"\n",
    "        class_ids = []\n",
    "        # Assuming Annotator class exists for visualization\n",
    "        self.annotator = Annotator(im0, 3, results[0].names)\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        clss = results[0].boxes.cls.cpu().tolist() # class IDs\n",
    "        names = results[0].names\n",
    "        print(names)\n",
    "\n",
    "        #each box for each class in the image\n",
    "        for box, cls in zip(boxes, clss): \n",
    "            class_ids.append(cls)\n",
    "            self.annotator.box_label(box, label=names[int(cls)], color=colors(\n",
    "                int(cls), True))  # Assuming colors function exists\n",
    "\n",
    "        print(class_ids)\n",
    "        return im0, class_ids\n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "           \n",
    "            \n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Executes object detection on video frames from a specified camera index, plotting bounding boxes and returning modified frames.\"\"\"\n",
    "        cap = cv2.VideoCapture(self.source)\n",
    "        assert cap.isOpened()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        frame_count = 0\n",
    "        while True:\n",
    "            self.start_time = time.time()\n",
    "            ret, im0 = cap.read()  # im0 is the individual frame.\n",
    "            assert ret\n",
    "            results = self.predict(im0)\n",
    "            im0, class_ids = self.plot_bboxes(results, im0) \n",
    "            \n",
    "             \n",
    "           \n",
    "\n",
    "            self.display_fps(im0)\n",
    "\n",
    "            mixer.init()\n",
    "            cv2.imshow('Perpetrators Detector', im0)\n",
    "            mixer.init()\n",
    "            if(self.alert(class_ids)):\n",
    "                 mixer.Sound(\"alert.wav\").play()\n",
    "            frame_count += 1\n",
    "            print(class_ids)\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Replace with your IP webcam URL if needed\n",
    "detector = ObjectDetection(0)\n",
    "\n",
    "# Call the object detection functionality\n",
    "detector()\n",
    "\n",
    "# Check for object detection and send email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
