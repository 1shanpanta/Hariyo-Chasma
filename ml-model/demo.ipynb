{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 862.4ms\n",
      "Speed: 6.3ms preprocess, 862.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "{0: 'carryload', 1: 'garbage', 2: 'load', 3: 'person'}\n",
      "[3.0, 3.0]\n",
      "Garbage thrower!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'mixer' has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 118\u001b[0m\n\u001b[0;32m    115\u001b[0m detector \u001b[38;5;241m=\u001b[39m ObjectDetection(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Call the object detection functionality\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m \u001b[43mdetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Check for object detection and send email\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 104\u001b[0m, in \u001b[0;36mObjectDetection.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay_fps(im0)\n\u001b[0;32m    103\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerpetrators Detector\u001b[39m\u001b[38;5;124m'\u001b[39m, im0)\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m frame_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(class_ids)\n",
      "Cell \u001b[1;32mIn[8], line 37\u001b[0m, in \u001b[0;36mObjectDetection.alert\u001b[1;34m(self, class_ids)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Send email alert\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGarbage thrower!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mmixer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m() \n\u001b[0;32m     38\u001b[0m     sound\u001b[38;5;241m=\u001b[39mmixer\u001b[38;5;241m.\u001b[39mSound(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m     sound\u001b[38;5;241m.\u001b[39mplay()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mixer' has no attribute 'init'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "import torch \n",
    "\n",
    "import mixer\n",
    "\n",
    "class ObjectDetection:\n",
    "    def __init__(self, source):\n",
    "        \"\"\"Initializes an ObjectDetection instance with a video source (webcam or IP camera URL).\"\"\"\n",
    "        self.source = source\n",
    "\n",
    "        # Model information\n",
    "        # Load YOLOv8n model weights\n",
    "        self.model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "\n",
    "        # Visual information\n",
    "        self.annotator = None\n",
    "        self.start_time = 0\n",
    "        self.end_time = 0\n",
    "\n",
    "        # Device information\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def predict(self, im0):\n",
    "        \"\"\"Run prediction using a YOLO model for the input image im0.\"\"\"\n",
    "        results = self.model(im0)\n",
    "        return results\n",
    "    def alert(self, class_ids):\n",
    "        \"\"\"Send an email alert if a person is detected in the frame.\"\"\"\n",
    "        for i in class_ids:\n",
    "            if i == 3:\n",
    "                # Send email alert\n",
    "                print(\"Garbage thrower!\")\n",
    "                mixer.init() \n",
    "                sound=mixer.Sound(\"alert.wav\")\n",
    "                sound.play()\n",
    "                break\n",
    "   \n",
    "\n",
    "    def display_fps(self, im0):\n",
    "        \"\"\"Displays the FPS on an image im0 by calculating and overlaying as white text on a black rectangle.\"\"\"\n",
    "        self.end_time = time.time()\n",
    "        fps = 1 / np.round(self.end_time - self.start_time, 2)\n",
    "        text = f'FPS: {int(fps)}'\n",
    "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]\n",
    "        gap = 10\n",
    "        cv2.rectangle(im0, (20 - gap, 70 - text_size[1] - gap),\n",
    "                      (20 + text_size[0] + gap, 70 + gap), (255, 255, 255), -1)\n",
    "        cv2.putText(im0, text, (20, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 2)\n",
    "\n",
    "    def plot_bboxes(self, results, im0):\n",
    "        \"\"\"Plots bounding boxes on an image given detection results; returns annotated image and class IDs.\"\"\"\n",
    "        class_ids = []\n",
    "        # Assuming Annotator class exists for visualization\n",
    "        self.annotator = Annotator(im0, 3, results[0].names)\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        clss = results[0].boxes.cls.cpu().tolist() # class IDs\n",
    "        names = results[0].names\n",
    "        print(names)\n",
    "\n",
    "        #each box for each class in the image\n",
    "        for box, cls in zip(boxes, clss): \n",
    "            class_ids.append(cls)\n",
    "            self.annotator.box_label(box, label=names[int(cls)], color=colors(\n",
    "                int(cls), True))  # Assuming colors function exists\n",
    "\n",
    "        print(class_ids)\n",
    "        return im0, class_ids\n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "           \n",
    "            \n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Executes object detection on video frames from a specified camera index, plotting bounding boxes and returning modified frames.\"\"\"\n",
    "        cap = cv2.VideoCapture(self.source)\n",
    "        assert cap.isOpened()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        frame_count = 0\n",
    "        while True:\n",
    "            self.start_time = time.time()\n",
    "            ret, im0 = cap.read()  # im0 is the individual frame.\n",
    "            assert ret\n",
    "            results = self.predict(im0)\n",
    "            im0, class_ids = self.plot_bboxes(results, im0) \n",
    "            \n",
    "             \n",
    "           \n",
    "\n",
    "            self.display_fps(im0)\n",
    "            cv2.imshow('Perpetrators Detector', im0)\n",
    "            self.alert(class_ids)\n",
    "            frame_count += 1\n",
    "\n",
    "            print(class_ids)\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Replace with your IP webcam URL if needed\n",
    "detector = ObjectDetection(0)\n",
    "\n",
    "# Call the object detection functionality\n",
    "detector()\n",
    "\n",
    "# Check for object detection and send email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
